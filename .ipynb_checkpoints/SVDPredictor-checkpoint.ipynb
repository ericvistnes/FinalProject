{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sixth-venture",
   "metadata": {},
   "source": [
    "# SVD Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-publication",
   "metadata": {},
   "source": [
    "Creating and testing the SVD Predictor model on our dataframe. First we need to split the data in train and test set, and then run GridSearchCV on the training set in order to find the best n factors value to pass into the SVD model creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "controversial-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from surprise import Reader, Dataset\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import xgboost as xbg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "international-release",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1248029</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>372233</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1080361</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MovieID  CustomerID  Rating\n",
       "0         1     1488844       3\n",
       "3         1       30878       4\n",
       "7         1     1248029       3\n",
       "19        1      372233       5\n",
       "20        1     1080361       3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_pickle(\"cleanedMovie.pkl\")\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "democratic-therapist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3751486, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train, movie_test = sklearn.model_selection.train_test_split(movie, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "korean-snapshot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3751486, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7882419</th>\n",
       "      <td>1582</td>\n",
       "      <td>826184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99705020</th>\n",
       "      <td>17580</td>\n",
       "      <td>1833576</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45681607</th>\n",
       "      <td>8171</td>\n",
       "      <td>395747</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22273012</th>\n",
       "      <td>4225</td>\n",
       "      <td>2361318</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55260630</th>\n",
       "      <td>10109</td>\n",
       "      <td>864647</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MovieID  CustomerID  Rating\n",
       "7882419      1582      826184       1\n",
       "99705020    17580     1833576       3\n",
       "45681607     8171      395747       5\n",
       "22273012     4225     2361318       4\n",
       "55260630    10109      864647       5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(movie_test.shape)\n",
    "movie_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "heavy-florence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15005940, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11836212</th>\n",
       "      <td>2284</td>\n",
       "      <td>1352912</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88353372</th>\n",
       "      <td>15717</td>\n",
       "      <td>574834</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977489</th>\n",
       "      <td>758</td>\n",
       "      <td>698147</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76706859</th>\n",
       "      <td>13923</td>\n",
       "      <td>1200886</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85305777</th>\n",
       "      <td>15134</td>\n",
       "      <td>2222815</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MovieID  CustomerID  Rating\n",
       "11836212     2284     1352912       4\n",
       "88353372    15717      574834       4\n",
       "3977489       758      698147       4\n",
       "76706859    13923     1200886       3\n",
       "85305777    15134     2222815       3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(movie_train.shape)\n",
    "movie_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "athletic-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))\n",
    "movieInput = pd.DataFrame()\n",
    "movieInput['CustomerID'] = movie_train['CustomerID']\n",
    "movieInput['MovieID'] = movie_train['MovieID']\n",
    "movieInput['Rating'] = movie_train['Rating']\n",
    "\n",
    "train_data = Dataset.load_from_df(movieInput, reader)\n",
    "trainset = train_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cardiovascular-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = list(zip(movie_test[\"CustomerID\"].values, movie_test[\"MovieID\"].values, movie_test[\"Rating\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sought-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_table = pd.DataFrame(columns = [\"Model\", \"Train_RMSE\", \"Test_RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "knowing-badge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4188866542182628"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-agreement",
   "metadata": {},
   "source": [
    "## Creating Fit and Prediction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "desirable-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_surprise(algo, trainset, testset, model_name):\n",
    "    start = datetime.now()\n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    pred_train = algo.test(trainset.build_testset())\n",
    "    \n",
    "    trainActual = np.array([p.r_ui for p in pred_train])\n",
    "    trainPred = np.array([p.est for p in pred_train]) \n",
    "    trainRMSE = np.sqrt(mean_squared_error(trainActual, trainPred))\n",
    "    \n",
    "    print(\"Train Data RMSE: {}\".format(trainRMSE))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    train = {\"RMSE\": trainRMSE, \"Prediction\": trainPred}\n",
    "    \n",
    "    pred_test = algo.test(testset)\n",
    "    testActual = np.array([p.r_ui for p in pred_test])\n",
    "    testPred = np.array([p.est for p in pred_test])\n",
    "    testRMSE = np.sqrt(mean_squared_error(testActual, testPred))\n",
    "    \n",
    "    print(\"Test Data RMSE: {}\".format(testRMSE))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    test = {\"RMSE\": testRMSE, \"Prediction\": testPred}\n",
    "    \n",
    "    print(\"Time Taken = \" + str(datetime.now() - start))\n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-vanilla",
   "metadata": {},
   "source": [
    "## Finding N Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-consumer",
   "metadata": {},
   "source": [
    "GridSearchCV cannot handle the amount of data we are passing through, so we will run GridSearchCV on a smaller portion of the dataset in order to return the best n_factors to pass into SVD. SVD will itself get the full dataset we are using. Only run the code below for GridSearchCV if you want to run through the whole code. The fit command can take up to an hour, and the results are always the same, so we can hard code in the parameter for SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "further-maldives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9141425899963144\n"
     ]
    }
   ],
   "source": [
    "params = { 'n_factors': [5, 10, 15, 20, 25, 30, 35, 40, 50]}\n",
    "grid = GridSearchCV(SVD, params, measures=['rmse'], cv=3, refit=True)\n",
    "grid.fit(Dataset.load_from_df(movieInput.iloc[:1500000], reader))\n",
    "print(grid.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-canadian",
   "metadata": {},
   "source": [
    "Of the N factors passed in, we can find the one that had the best RMSE and use that in the SVD model. Below, we use that directly from the calculation above. In the following class file, we use the value as a static variable in order to minimize processing time on unnecessary calculations. The results of grid.best_params['rmse']['n_factors'] are always 5, so feel free to input that into the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "athletic-romantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Train Data RMSE: 0.8198083205483772\n",
      "\n",
      "\n",
      "Test Data RMSE: 0.828587192328288\n",
      "\n",
      "\n",
      "Time Taken = 0:10:29.761314\n"
     ]
    }
   ],
   "source": [
    "algo = SVD(n_factors = grid.best_params['rmse']['n_factors'], biased=True, verbose=True)\n",
    "train_result, test_result = run_surprise(algo, trainset, testset, \"SVD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-housing",
   "metadata": {},
   "source": [
    "The best results for the test data are RMSE of 0.829, which is an extremely good RMSE for the Netflix Prize Data! Of course, the data may be somewhat skewed from only taking the most active users and popular movies. However, for our data of active users, this is highly effective! We can test below on less active users to see the RMSE for users we didn't include."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-employee",
   "metadata": {},
   "source": [
    "## Testing on Unused Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-track",
   "metadata": {},
   "source": [
    "Here we read in some of the rest of the data that was not passed into the pickle file in the beginning. We test for the RMSE of this test data using the SVD algorithm above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "voluntary-whole",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.004805e+08</td>\n",
       "      <td>1.004805e+08</td>\n",
       "      <td>1.004805e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.070915e+03</td>\n",
       "      <td>1.322489e+06</td>\n",
       "      <td>3.604290e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.131891e+03</td>\n",
       "      <td>7.645368e+05</td>\n",
       "      <td>1.085219e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.677000e+03</td>\n",
       "      <td>6.611980e+05</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.051000e+03</td>\n",
       "      <td>1.319012e+06</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.363500e+04</td>\n",
       "      <td>1.984455e+06</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.777000e+04</td>\n",
       "      <td>2.649429e+06</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MovieID    CustomerID        Rating\n",
       "count  1.004805e+08  1.004805e+08  1.004805e+08\n",
       "mean   9.070915e+03  1.322489e+06  3.604290e+00\n",
       "std    5.131891e+03  7.645368e+05  1.085219e+00\n",
       "min    1.000000e+00  6.000000e+00  1.000000e+00\n",
       "25%    4.677000e+03  6.611980e+05  3.000000e+00\n",
       "50%    9.051000e+03  1.319012e+06  4.000000e+00\n",
       "75%    1.363500e+04  1.984455e+06  4.000000e+00\n",
       "max    1.777000e+04  2.649429e+06  5.000000e+00"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "movie = pd.read_csv(cwd + \"/data/final.csv\")\n",
    "movie.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "municipal-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = movie.drop(columns=['Date'])\n",
    "\n",
    "reduced_data['MovieID'] = reduced_data['MovieID'].astype('int16')\n",
    "reduced_data['CustomerID'] = reduced_data['CustomerID'].astype('int32')\n",
    "reduced_data['Rating'] = reduced_data['Rating'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "surrounded-billion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of original data: (100480507, 3)\n",
      "shape of data_popular_movies (100400918, 3)\n",
      "No. of movies which are rated more than 100 times: 16795\n"
     ]
    }
   ],
   "source": [
    "movie_freq = pd.DataFrame(reduced_data.groupby('MovieID').size(),columns=['count'])\n",
    "threshold = 100\n",
    "\n",
    "popular_movies = list(set(movie_freq.query('count>=@threshold').index))\n",
    "\n",
    "# ratings df after dropping non popular movies\n",
    "data_popular_movies = reduced_data[reduced_data.MovieID.isin(popular_movies)]\n",
    "\n",
    "print('shape of original data:', reduced_data.shape)\n",
    "print('shape of data_popular_movies', data_popular_movies.shape)\n",
    "print(\"No. of movies which are rated more than 100 times:\", len(popular_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "interesting-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce data_popular_movie to only have movies that are in movie\n",
    "movieList = movie.MovieID.tolist()\n",
    "popMoviesTest = data_popular_movies[data_popular_movies.MovieID.isin(movieList)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-period",
   "metadata": {},
   "source": [
    "The below code takes a very long time to run as well, as it is 100,000,000 rows of data being passed in. You can uncomment the line near the top to reduce the dataset to a more manageable size. If not, it takes about an hour to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "spiritual-composer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data RMSE: 0.9949435296768612\n",
      "\n",
      "\n",
      "Time Taken = 1:04:08.393445\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "reducedtestset = list(zip(popMoviesTest[\"CustomerID\"].values, popMoviesTest[\"MovieID\"].values, popMoviesTest[\"Rating\"].values))\n",
    "#reducedtestset = reducedtestset.iloc[:2000000]\n",
    "\n",
    "pred_test = algo.test(reducedtestset)\n",
    "testActual = np.array([p.r_ui for p in pred_test])\n",
    "testPred = np.array([p.est for p in pred_test])\n",
    "testRMSE = np.sqrt(mean_squared_error(testActual, testPred))\n",
    "    \n",
    "print(\"Test Data RMSE: {}\".format(testRMSE))\n",
    "print(\"\\n\")\n",
    "    \n",
    "test = {\"RMSE\": testRMSE, \"Prediction\": testPred}\n",
    "    \n",
    "print(\"Time Taken = \" + str(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-tampa",
   "metadata": {},
   "source": [
    "Based on the RMSE from the test set we just ran, our algorithm is definitely biased toward users who have rated very frequently. There is likely a high level of correlation between those users, which affects our results. This proves that our algorithm is highly effective for those users, but only average for users who do not rate in the top percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-morning",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-technique",
   "metadata": {},
   "source": [
    "Take all the information we gathered, the functions we built, and the models we created, and put them all into one class. The class saves algorithms as pickle files to be reused later without having to calculate the model and algorithm all over again. The class also has no testset, as there is no need for verification at this stage- only fitting the model and predicting values for the given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "gross-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "from surprise import Reader, Dataset\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class SVDPredictor:\n",
    "    error_table = pd.DataFrame(columns = [\"Model\", \"Train_RMSE\", \"Test_RMSE\"])\n",
    "    \n",
    "    #Class takes in final.csv as a whole as a DataFrame\n",
    "    def __init__(self, data):\n",
    "        self.movie = data\n",
    "        self.createAlgorithmFromData()\n",
    "        \n",
    "    def createAlgorithmFromData(self):\n",
    "        #check if algo and trainset/train_data files are already created\n",
    "        file = pathlib.Path('svd.pickle')\n",
    "        if not file.exists():\n",
    "            self._reduceDataSize()\n",
    "            self._splitMovie()\n",
    "            self._createTrainSet()\n",
    "        self._run_surprise()\n",
    "        \n",
    "    def predict(self, userID, movieID):\n",
    "        #use algo to predict rating. Return predicted rating\n",
    "        return self.algo.predict(userID, movieID)\n",
    "    \n",
    "    def _splitMovie(self):\n",
    "        self.movie = self.movie.iloc[:1500000]\n",
    "        \n",
    "    def _createTrainSet(self):\n",
    "        reader = Reader(rating_scale=(1,5))\n",
    "        movieInput = pd.DataFrame()\n",
    "        movieInput['CustomerID'] = self.movie['CustomerID']\n",
    "        movieInput['MovieID'] = self.movie['MovieID']\n",
    "        movieInput['Rating'] = self.movie['Rating']\n",
    "\n",
    "        self.train_data = Dataset.load_from_df(movieInput, reader)\n",
    "        self.trainset = self.train_data.build_full_trainset()\n",
    "        #write to a file\n",
    "    \n",
    "    def _reduceDataSize(self):\n",
    "        self.movie['Date'] = self.movie['Date'].astype('category')\n",
    "        self.movie['MovieID'] = self.movie['MovieID'].astype('int16')\n",
    "        self.movie['CustomerID'] = self.movie['CustomerID'].astype('int32')\n",
    "        self.movie['Rating'] = self.movie['Rating'].astype('int8')\n",
    "    \n",
    "    def _run_surprise(self): \n",
    "        file = pathlib.Path('svd.pickle')\n",
    "        if file.exists():\n",
    "            with open('svd.pickle', 'rb') as f:\n",
    "                self.algo = pickle.load(f)\n",
    "        else:\n",
    "            self.algo = SVD(n_factors = 5, biased=True, verbose=True)\n",
    "            self.algo = self.algo.fit(self.trainset)\n",
    "            with open('svd.pickle', 'wb') as f:\n",
    "                pickle.dump(self.algo, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-paragraph",
   "metadata": {},
   "source": [
    "Let's now instantiate the class we just created above with our curated data set, and then test it on a random CustomerID and MovieID! In the actual application of a recommender, we would want to set a specific CustomerID, but allow the MovieID to vary to get our ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "interesting-roads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "3.9115833649385836\n"
     ]
    }
   ],
   "source": [
    "svd = SVDPredictor(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ultimate-reverse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.340447112643969\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction for Customer 1 and Movie 5: \", svd.predict(1, 5).est)\n",
    "print(\"Prediction for Customer 1 and Movie 16378: \", svd.predict(7, 16378).est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-sapphire",
   "metadata": {},
   "source": [
    "## Creating a Mini-Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-clock",
   "metadata": {},
   "source": [
    "Though we already have 2 models for recommenders, we can also use the SVD model as a recommender for a Customer at a time. Below is code to recommend 10 movies to a given Customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ancient-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendFor(customerID, movieIDs, model):\n",
    "    predictions = []\n",
    "    for movie in movieIDs:\n",
    "        predictions.append(model.predict(customerID, movie).est)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "suited-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = recommendFor(1, movie.MovieID.unique().tolist(), svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "floating-fighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17765</th>\n",
       "      <td>Where the Wild Things Are and Other Maurice Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17766</th>\n",
       "      <td>Fidel Castro: American Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17767</th>\n",
       "      <td>Epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17768</th>\n",
       "      <td>The Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17769</th>\n",
       "      <td>Alien Hunter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17770 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title\n",
       "0                                        Dinosaur Planet\n",
       "1                             Isle of Man TT 2004 Review\n",
       "2                                              Character\n",
       "3                           Paula Abdul's Get Up & Dance\n",
       "4                               The Rise and Fall of ECW\n",
       "...                                                  ...\n",
       "17765  Where the Wild Things Are and Other Maurice Se...\n",
       "17766                  Fidel Castro: American Experience\n",
       "17767                                              Epoch\n",
       "17768                                        The Company\n",
       "17769                                       Alien Hunter\n",
       "\n",
       "[17770 rows x 1 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title = pd.read_csv(cwd + \"/data/movie_titles.csv\", encoding='unicode_escape', usecols=[2], header=None)\n",
    "movie_title.columns = ['title']\n",
    "movie_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "sporting-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendedMovies(count, preds):\n",
    "    movieAndRating = {}\n",
    "    copyPreds = preds\n",
    "    for i in range(count):\n",
    "        index = copyPreds.index(max(copyPreds))\n",
    "        maxPred = max(copyPreds)\n",
    "        title = movie_title.iloc[index:index+1]['title'][index]\n",
    "        movieAndRating[title] = maxPred\n",
    "        copyPreds.pop(index)\n",
    "    return movieAndRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "composed-destination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Animation Legend: Winsor McCay': 3.9761161781499674,\n",
       " 'Winnie the Pooh: Springtime with Roo': 3.9734730585465985,\n",
       " 'Fatal Beauty': 3.9620931808825235,\n",
       " 'The Great Race': 3.959445030171472,\n",
       " 'Mann': 3.9564895830237434,\n",
       " \"That '70s Show: Season 1\": 3.952919822356805,\n",
       " 'Lost in the Pershing Point Hotel': 3.9486325753206364,\n",
       " 'Pressure': 3.9241229015910952,\n",
       " 'The Hunchback of Notre Dame II': 3.9224312892992375,\n",
       " 'Chain of Command': 3.9193358298762853}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendedMovies(10, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-reason",
   "metadata": {},
   "source": [
    "The final product is a recommender that returns the count of top movies for the chosen Customer, and gives the predicted rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-cabinet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
